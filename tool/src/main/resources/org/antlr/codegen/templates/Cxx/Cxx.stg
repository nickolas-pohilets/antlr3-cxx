/*
 [The "BSD license"]

 Copyright (c) 20013-2015 Nickolas Pohilets
 
 Copyright (c) 2005-2009 Jim Idle, Temporal Wave LLC
 http://www.temporal-wave.com
 http://www.linkedin.com/in/jimidle

 All rights reserved.

 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions
 are met:
 1. Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
 2. Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.
 3. The name of the author may not be used to endorse or promote products
    derived from this software without specific prior written permission.

 THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

cxxTypeInitMap ::= [
	"int"		    : "0",             // Integers     start out being 0
	"long"		    : "0",             // Longs        start out being 0
	"float"		    : "0.0",           // Floats       start out being 0
	"double"	    : "0.0",           // Doubles      start out being 0
	"bool"          : "false",         // Booleans     start out being false
	"byte"		    : "0",             // Bytes        start out being 0
	"short"		    : "0",             // Shorts       start out being 0
	"char"		    : "0"              // Chars        start out being 0
]

leadIn(type) ::=
<<
/** \file
 *  This <type> file was generated by ANTLR version <ANTLRVersion>
 *
 *     -  From the grammar source file : <fileName>
 *     -                            On : <generatedTimestamp>
<if(LEXER)>
 *     -                 for the lexer : <name>
<endif>
<if(PARSER)>
 *     -                for the parser : <name>
<endif>
<if(TREE_PARSER)>
 *     -           for the tree parser : <name>
<endif>
 *
 * Editing it, at least manually, is not wise.
 *
 * C++ language generator and runtime by Nickolas Pohilets, pohilets[at]gmail.com,
 * based on C language generator and runtime by Jim Idle, jimi|hereisanat|idle|dotgoeshere|ws.
 *
>>

/** The overall file structure of a recognizer; stores methods for rules
 *  and cyclic DFAs plus support code.
 */
outputFile( LEXER,
            PARSER,
            TREE_PARSER,
            actionScope,
            actions,
            docComment,
            recognizer,
            name,
            tokens,
            tokenNames,
            rules,
            cyclicDFAs,
            bitsets,
            buildTemplate,
            buildAST,
            rewriteMode,
            profile,
            backtracking,
            synpreds,
            memoize,
            numRules,
            fileName,
            ANTLRVersion,
            generatedTimestamp,
            trace,
            scopes,
            superClass,
            literals,
            namespaceComponents
            ) ::=
<<
<leadIn("source")>
*/

<actions.(actionScope).source_preincludes>
#include "<name>.hpp"
<recognizer.grammar.delegators: {g|#include "<g.recognizerName>.hpp"}; separator="\n">
<actions.(actionScope).source_postincludes>

<docComment>

<if(namespaceComponents)>
<namespaceComponents:{ns | namespace <ns> {<\n>}>
<endif>

using antlr3::isBetween;

<actions.(actionScope).predefinitions>

<if(literals)>
/** String literals used by <name> that we must do things like matchs() with.
 *  C will normally just lay down 8 bit characters, and you can use L"xxx" to
 *  get wchar_t, but wchar_t is 16 bits on Windows, which is not UTF32 and so
 *  we perform this little trick of defining the literals as arrays of UINT32
 *  and passing in the address of these.
 */
<literals:{it | static antlr3::Char	lit_<i>[]  = <it>;}; separator="\n">

<endif>

<recognizer>

<actions.(actionScope).postdefinitions>

<if(namespaceComponents)>
<reverse(namespaceComponents):{ns | \} // namespace <ns><\n>}>
<endif>
>>

headerFileExtension() ::= ".hpp"

headerFile( LEXER,
            PARSER,
            TREE_PARSER,
            actionScope,
            actions,
            docComment,
            recognizer,
            name,
            tokens,
            tokenNames,
            rules,
            cyclicDFAs,
            bitsets,
            buildTemplate,
            buildAST,
            rewriteMode,
            profile,
            backtracking,
            synpreds,
            memoize,
            numRules,
            fileName,
            ANTLRVersion,
            generatedTimestamp,
            trace,
            scopes,
            superClass,
            literals,
            namespaceComponents
        ) ::=
<<
<leadIn("header")>
<if(PARSER)>
 * The parser <mainName()> has the callable functions (rules) shown below,
<endif>
<if(LEXER)>
 * The lexer <mainName()> has the callable functions (rules) shown below,
<endif>
<if(TREE_PARSER)>
 * The tree parser <mainName()> has the callable functions (rules) shown below,
<endif>
 * which will invoke the code for the associated rule in the source grammar
 * assuming that the input stream is pointing to a token/text stream that could begin
 * this rule.
 *
 * For instance if you call the first (topmost) rule in a parser grammar, you will
 * get the results of a full parse, but calling a rule half way through the grammar will
 * allow you to pass part of a full token stream to the parser, such as for syntax checking
 * in editors and so on.
 *
<if(LEXER)>
 * As this is a generated lexer, it is unlikely you will call it 'manually'. However
 * the methods are provided anyway.
<endif>
 * The return type for any particular rule is of course determined by the source
 * grammar file.
 */

#ifndef	_<name>_hpp_
#define _<name>_hpp_

<actions.(actionScope).header_preincludes>
#include  \<antlr3/antlr3.hpp>
<if(recognizer.grammar.delegates)>
<recognizer.grammar.delegates: {g|#include "<g.recognizerName>.hpp"}; separator="\n">
<endif>
<actions.(actionScope).header_postincludes>
<if(backtracking)>

/* ========================
 * BACKTRACKING IS ENABLED
 * ========================
 */
<endif>

<if(namespaceComponents)>
<namespaceComponents:{ns | namespace <ns> {<\n>}>
<endif>
<actions.(actionScope).before_class>
<rules:{r |<headerReturnScope(ruleDescriptor=r.ruleDescriptor,...)>}>
<scopes:{it | <if(it.isDynamicGlobalScope)><globalAttributeScopeDecl(it)><endif>}>
<rules:{r |<ruleAttributeScopeDecl(scope=r.ruleDescriptor.ruleScope)>}>
<if(recognizer.grammar.delegators)>
// Forward declarations for delegator classes
<recognizer.grammar.delegators: {g|class <g.recognizerName>;<\n>}>
<endif>

<if(PARSER)>
class <name> : public antlr3::Parser
<endif>
<if(LEXER)>
class <name> : public antlr3::Lexer
<endif>
<if(TREE_PARSER)>
class <name> : public antlr3::TreeParser
<endif>
{
<actions.(actionScope).declarations>
public:
    /// Symbolic definitions of all the tokens that the recognizer will work with.
    enum Tokens : std::uint32_t {
        <tokens:{it |<it.name> = <it.type>}; separator=",\n">
    };

    <name>(<inputType()> instream<recognizer.grammar.delegators:{g|, <g.recognizerName> * <g:delegateName()>}>);
    <name>(<inputType()> instream, antlr3::RecognizerSharedStatePtr state<recognizer.grammar.delegators:{g|, <g.recognizerName> * <g:delegateName()>}>);
    ~<name>();

<if(LEXER)>
    <rules:{r | <if(!r.ruleDescriptor.isSynPred)><headerReturnType(ruleDescriptor=r.ruleDescriptor)> m<r.ruleDescriptor.name>(<r.ruleDescriptor.parameterScope:parameterScope()>);<endif>}; separator="\n">
<endif>
<if(!LEXER)>
    <rules:{r | <headerReturnType(ruleDescriptor=r.ruleDescriptor)> <r.ruleDescriptor.name>(<r.ruleDescriptor.parameterScope:parameterScope()>);}; separator="\n">
<! generate rule/method definitions for imported rules so they
   appear to be defined in this recognizer. !>
<if(recognizer.grammar.delegatedRules)>
    // Delegated rules
<recognizer.grammar.delegatedRules:{ruleDescriptor|
    <headerReturnType(ruleDescriptor)> <ruleDescriptor.name>(<ruleDescriptor.parameterScope:parameterScope()>);}; separator="\n">
<endif>
<endif>

    const char * grammarFileName();
    void reset();

private:
    <recognizer.grammar.delegates:{g|std::shared_ptr\<<g.recognizerName>\> <g:delegateName()>_;}; separator="\n">
    <recognizer.grammar.delegators:{g|<g.recognizerName> * <g:delegateName()>_;}; separator="\n">
    <scopes:{it | <if(it.isDynamicGlobalScope)><globalAttributeScopeDef(it)><endif>}; separator="\n">
    <rules: {r |<if(r.ruleDescriptor.ruleScope)><ruleAttributeScopeDef(scope=r.ruleDescriptor.ruleScope)><endif>}; separator="\n">
<if(cyclicDFAs)>
    friend class <name>_SST_Func_Provider;
    <cyclicDFAs:declDFA_SST()>
<endif>
<@members><@end>
<@dbgMembers><@end>
};

<if(!recognizer.grammar.grammarIsRoot)>
extern char const * const <recognizer.grammar.composite.rootGrammar.recognizerName>TokenNames[];
<endif>

<actions.(actionScope).after_class>

<if(namespaceComponents)>
<reverse(namespaceComponents):{ns | \} // namespace <ns><\n>}>
<endif>

#endif // _<name>_hpp_

>>

inputType() ::= <%
<if(LEXER)>antlr3::CharStreamPtr<endif>
<if(PARSER)>antlr3::CommonTokenStreamPtr<endif>
<if(TREE_PARSER)>antlr3::CommonTreeNodeStreamPtr<endif>
%>

grammarType() ::= <%
<if(PARSER)>parser<endif>
<if(LEXER)>lexer<endif>
<if(TREE_PARSER)>tree parser<endif>
%>

mainName() ::= <%
<if(PARSER)><name><endif>
<if(LEXER)><name><endif>
<if(TREE_PARSER)><name><endif>
%>

headerReturnScope(ruleDescriptor) ::= "<returnScope(...)>"

headerReturnType(ruleDescriptor) ::= <<
<if(LEXER)><\\>
<if(!ruleDescriptor.isSynPred)>void<else><returnType()><endif><\\>
<else><\\>
<returnType()><\\>
<endif>
>>

// Produce the lexer output
//
lexer(  grammar,
		name,
        tokens,
        scopes,
        rules,
        numRules,
        filterMode,
        superClass,
        labelType="antlr3::CommonTokenPtr") ::= <<

#ifdef EOF
#undef EOF
#endif
#define EOF antlr3::TokenEof

/* =========================================================================
 * Lexer matching rules end.
 * =========================================================================
 */
<name>::~<name>()
{
<actions.(actionScope).dtor_body>
}

void <name>::reset()
{
    Lexer::reset();
}

/** \brief Name of the grammar file that generated this code
 */
static const char fileName[] = "<fileName>";

/** \brief Return the name of the grammar file that generated this code.
 */
const char * <name>::grammarFileName()
{
	return fileName;
}

<name>::<name>(<inputType()> instream<grammar.delegators:{g|, <g.recognizerName> * <g:delegateName()>}>)
    : <name>(instream, NULL<grammar.delegators:{g|, <g:delegateName()>}>)
{
}

<name>::<name>(antlr3::CharStreamPtr instream, antlr3::RecognizerSharedStatePtr state<grammar.delegators:{g|, <g.recognizerName> * <g:delegateName()>}>)
    : Lexer(instream, state)
<if(grammar.directDelegates)>
    // Initialize the lexers that we are going to delegate some functions to.
    <grammar.directDelegates:
         {g|, <g:delegateName()>_(new <g.recognizerName>(instream, state_, this<grammar.delegators:{g|, <g:delegateName()>}>);};
         separator="\n">
<endif>
<actions.(actionScope).initializers>
{
<if(filterMode)>
    antlr3::BaseRecognizer::filteringMode_ = true;
<endif>
<if(memoize)>
<if(grammar.grammarIsRoot)>
    // Create a LIST for recording rule memos.
    //
    state_->ruleMemo = antlr3IntTrieNew(15);	/* 16 bit depth is enough for 32768 rules! */
<endif>
<endif>
<if(grammar.delegators)>
	// Install the pointers back to lexers that will delegate us to perform certain functions for them.
	<grammar.delegators:
         {g|<g:delegateName()>_ = <g:delegateName()>;}; separator="\n">
<endif>
<actions.(actionScope).ctor_body>
}

<if(cyclicDFAs)>

class <name>_SST_Func_Provider
{
public:
<cyclicDFAs:dfa_sst_func()> <! Forward declare DFA specials !>
};

/* =========================================================================
 * DFA tables for the lexer
 */
<cyclicDFAs:cyclicDFA()> <! dump tables for all DFA !>
/* =========================================================================
 * End of DFA tables for the lexer
 */
<endif>

/* =========================================================================
 * Functions to match the lexer grammar defined tokens from the input stream
 */

<rules; separator="\n\n">

/* =========================================================================
 * Lexer matching rules end.
 * =========================================================================
 */
<if(synpreds)>

/* =========================================================================
 * Lexer syntactic predicates
 */
<synpreds:{p | <lexerSynpred(predname=p)>}>
/* =========================================================================
 * Lexer syntactic predicates end.
 * =========================================================================
 */
<endif>

/* End of Lexer code
 * ================================================
 * ================================================
 */

>>

actionGate() ::= "state_->backtracking == 0"

filteringActionGate() ::= "state_->backtracking == 1"

/** How to generate a parser */
genericParser(  grammar,
				name,
                scopes,
                tokens,
                tokenNames,
                rules,
                numRules,
                bitsets,
                inputStreamType,
                superClass,
                labelType,
				members,
				rewriteElementType, filterMode,
                ASTLabelType="antlr3::ItemPtr"
              ) ::= <<

#ifdef EOF
#undef EOF
#endif
#define EOF antlr3::TokenEof

<if(grammar.grammarIsRoot)>
/** \brief Table of all token names in symbolic order, mainly used for
 *         error reporting.
 */
antlr3::ConstString const <name>TokenNames[<length(tokenNames)>+4] = {
    ANTLR3_T("\<invalid>"),  // String to print to indicate an invalid token
    ANTLR3_T("\<EOR>"),
    ANTLR3_T("\<DOWN>"),
    ANTLR3_T("\<UP>"),
    <tokenNames:{it|ANTLR3_T(<it>)}; separator=",\n">
};
<endif>

<@members><@end>

/** \brief Name of the grammar file that generated this code
 */
static const char fileName[] = "<fileName>";

/** \brief Return the name of the grammar file that generated this code.
 */
const char * <name>::grammarFileName()
{
	return fileName;
}
/** \brief Create a new <name> parser and return a context for it.
 *
 * \param[in] instream Pointer to an input stream interface.
 *
 * \return Pointer to new parser context upon success.
 */
<name>::<name>(<inputStreamType> instream<grammar.delegators:{g|, <g.recognizerName> * <g:delegateName()>}>)
    : <name>(instream, NULL<grammar.delegators:{g|, <g:delegateName()>}>)
{
}

/** \brief Create a new <name> parser and return a context for it.
 *
 * \param[in] instream Pointer to an input stream interface.
 *
 * \return Pointer to new parser context upon success.
 */
<name>::<name>(<inputStreamType> instream, antlr3::RecognizerSharedStatePtr state<grammar.delegators:{g|, <g.recognizerName> * <g:delegateName()>}>)
<if(PARSER)>
    : Parser(instream, state)
<endif>
<if(TREE_PARSER)>
    : TreeParser(instream, state)
<endif>
<if(grammar.directDelegates)>
    // Initialize the parsers that we are going to delegate some functions to.
    <grammar.directDelegates:
        {g|, <g:delegateName()>_(new <g.recognizerName>(instream, state_, this<grammar.delegators:{g|, <g:delegateName()>}>))};
        separator="\n">
<endif>
<if(grammar.delegators)>
    // Install the pointers back to parsers that will delegate us to perform certain functions for them.
    <grammar.delegators:
         {g|, <g:delegateName()>_(<g:delegateName()>)}; separator="\n">
<endif>
<actions.(actionScope).initializers>
{
    <@apifuncs>
    <@end>
<if(memoize)>
<if(grammar.grammarIsRoot)>
    /* Create a LIST for recording rule memos.
     */
     state_->ruleMemo    = antlr3IntTrieNew(15);	/* 16 bit depth is enough for 32768 rules! */<\n>
<endif>
<endif>
    /* Install the token table
     */
    state_->tokenNames   = <grammar.composite.rootGrammar.recognizerName>TokenNames;

    <@debugStuff()>
<actions.(actionScope).ctor_body>
}

void <name>::reset()
{
<if(PARSER)>
    Parser::reset();
<endif>
<if(TREE_PARSER)>
    TreeParser::reset();
<endif>
}

/** Free the parser resources
 */
 <name>::~<name>()
 {
    <@cleanup>
    <@end>

    <actions.(actionScope).dtor_body>
}
    <members>

// Declare bitsets defining follow sets for error recovery
//
<bitsets:{it | <bitsetDeclare(name={FOLLOW_<it.name>_in_<it.inName><it.tokenIndex>},
                    words64=it.bits)>}>


<if(cyclicDFAs)>

/* =========================================================================
 * DFA tables for the parser
 */
<cyclicDFAs:cyclicDFA()> <! dump tables for all DFA !>
/* =========================================================================
 * End of DFA tables for the parser
 */
<endif>

/* ==============================================
 * Parsing rules
 */
<rules; separator="\n\n">
<if(grammar.delegatedRules)>

// Delegated methods that appear to be a part of this parser

<grammar.delegatedRules:{ruleDescriptor|
<returnType()> <name>::<ruleDescriptor.name>(<ruleDescriptor.parameterScope:parameterScope()>)
{
    <if(ruleDescriptor.hasReturnValue)>return <endif><ruleDescriptor.grammar:delegateName()>_-><ruleDescriptor.name>(<ruleDescriptor.parameterScope.attributes:{a|<a.name>}; separator=", ">);
\}}; separator="\n">

<endif>
/* End of parsing rules
 * ==============================================
 */

/* ==============================================
 * Syntactic predicates
 */
<synpreds:{p | <synpred(predname=p)>}>
/* End of syntactic predicates
 * ==============================================
 */





>>

parser(	grammar,
		name,
		scopes,
		tokens,
		tokenNames,
		rules,
		numRules,
		bitsets,
		ASTLabelType,
		superClass="Parser",
		labelType="antlr3::CommonTokenPtr",
		members={<actions.parser.members>}
		) ::= <<
<genericParser(inputStreamType="antlr3::CommonTokenStreamPtr", rewriteElementType="Token", ...)>
>>

/** How to generate a tree parser; same as parser except the input
 *  stream is a different type.
 */
treeParser(	grammar,
			name,
			scopes,
			tokens,
			tokenNames,
			globalAction,
			rules,
			numRules,
			bitsets,
			filterMode,
			labelType={<ASTLabelType>},
			ASTLabelType="antlr3::ItemPtr",
			superClass="TreeParser",
			members={<actions.treeparser.members>}
			) ::= <<
<genericParser(inputStreamType="antlr3::CommonTreeNodeStreamPtr", rewriteElementType="NODE", ...)>
>>

/** A simpler version of a rule template that is specific to the imaginary
 *  rules created for syntactic predicates.  As they never have return values
 *  nor parameters etc..., just give simplest possible method.  Don't do
 *  any of the normal memoization stuff in here either; it's a waste.
 *  As predicates cannot be inlined into the invoking rule, they need to
 *  be in a rule by themselves.
 */
synpredRule(ruleName, ruleDescriptor, block, description, nakedBlock) ::=
<<
// $ANTLR start <ruleName>
static void <ruleName>_fragment(p<name> ctx <ruleDescriptor.parameterScope:parameterScope()>)
{
	<ruleLabelDefs()>
	<ruleLabelInitializations()>
<if(trace)>
    traceIn(ANTLR3_T("<ruleName>_fragment"), <ruleDescriptor.index>);
    <block>
    traceOut(ANTLR3_T("<ruleName>_fragment"), <ruleDescriptor.index>);
<else>
    <block>
<endif>
<ruleCleanUp()>
}
// $ANTLR end <ruleName>
>>

synpred(predname) ::= <<
static bool <predname>(p<name> ctx)
{
    state_->backtracking++;
    <@start()>
    antlr3::Marker start = input_->mark();
    <predname>_fragment(ctx); // can never throw exception
    bool success = !state_->failed;
    input_->rewind(start);
    <@stop()>
    state_->backtracking--;
    state_->failed = false;
    return success;
}<\n>
>>

lexerSynpred(predname) ::= <<
<synpred(predname)>
>>

ruleMemoization(rname) ::= <<
<if(memoize)>
if (state_->backtracking > 0 && alreadyParsedRule(<ruleDescriptor.index>))
{
<if(ruleDescriptor.hasMultipleReturnValues)>
<if(!ruleDescriptor.isSynPred)>
	retval.start = 0;<\n>
<endif>
<endif>
    <(ruleDescriptor.actions.after):execAfter()>
    <finalCode(finalBlock=finally)>
<if(!ruleDescriptor.isSynPred)>
    <scopeClean()><\n>
<endif>
    return <ruleReturnValue()>;
}
<endif>
>>

/** How to test for failure and return from rule */
checkRuleBacktrackFailure() ::= <<
if (state_->error)
{
    goto rule<ruleDescriptor.name>Ex;
}
<if(backtracking)>
if (state_->failed)
{
    <scopeClean()>
    <@debugClean()>
    return <ruleReturnValue()>;
}
<endif>
>>

/** This rule has failed, exit indicating failure during backtrack */
ruleBacktrackFailure() ::= <<
<if(backtracking)>
if (state_->backtracking > 0)
{
    state_->failed = <true_value()>;
    <scopeClean()>
    return <ruleReturnValue()>;
}
<endif>
>>

/** How to generate code for a rule.  This includes any return type
 *  data aggregates required for multiple return values.
 */
rule(ruleName,ruleDescriptor,block,emptyRule,description,exceptions,finally,memoize) ::= <<
/**
 * $ANTLR start <ruleName>
 * <fileName>:<description>
 */
<returnType()> <name>::<ruleName>(<ruleDescriptor.parameterScope:parameterScope()>)
{
    <if(trace)>traceIn(ANTLR3_T("<ruleName>"), <ruleDescriptor.index>);<endif>
    <ruleDeclarations()>
    <ruleDescriptor.actions.declarations>
    <ruleLabelDefs()>
    <ruleDescriptor.useScopes:{it |<scopeStack(sname=it,...)>.emplace_back();}; separator="\n">
    <ruleDescriptor.ruleScope:{it |<scopeStack(sname=it.name,...)>.emplace_back();}; separator="\n">
    <ruleDescriptor.actions.init>
    <ruleMemoization(rname=ruleName)>
    <ruleLabelInitializations()>
    <@preamble()>
    {
        <block>
    }

    <ruleCleanUp()>
<if(exceptions)>
    if (state_->error)
    {
	<exceptions:{e|<catch(decl=e.decl,action=e.action)><\n>}>
    }
    else
    {
	<(ruleDescriptor.actions.after):execAfter()>
    }
<else>
    <if(!emptyRule)>
        <if(actions.(actionScope).rulecatch)>
            <actions.(actionScope).rulecatch>
        <else>
            if (state_->error)
            {
                reportError();
                recover();
                <@setErrorReturnValue()>
            }
            <if(ruleDescriptor.actions.after)>
            else
            {
                <(ruleDescriptor.actions.after):execAfter()>
            }<\n>
            <endif>
        <endif>
    <endif>
<endif>

    <if(trace)>traceOut(ANTLR3_T("<ruleName>"), <ruleDescriptor.index>);<endif>
    <memoize()>
<if(finally)>
    <finalCode(finalBlock=finally)>
<endif>
    <scopeClean()>
    <@postamble()>
    return <ruleReturnValue()>;
}
/* $ANTLR end <ruleName> */
>>

finalCode(finalBlock) ::= <<
{
    <finalBlock>
}

>>

catch(decl,action) ::= <<
/* catch(decl,action)
 */
{
    <e.action>
}

>>

ruleDeclarations() ::= <<
<if(ruleDescriptor.hasMultipleReturnValues)>
<returnType()> retval = {
<if(!ruleDescriptor.isSynPred)>
    .start = LT(1),
    .stop = LT(1),
<endif>
    <ruleDescriptor.returnScope.attributes:{ a |<initField(a.type, a.name, a.initValue)>}>
};
<elseif(ruleDescriptor.returnScope)>
<ruleDescriptor.returnScope.attributes:{ a |<initLocalVar(a.type, a.name, a.initValue)>}>
<endif>
<if(memoize)>
antlr3::Index <ruleDescriptor.name>_StartIndex = input_->index();
<endif>
>>

initField(type, name, init) ::= <<
<if(init)>.<name> = <init>,<elseif(cxxTypeInitMap.(type))>.name = <cxxTypeInitMap.(type)>,<endif>
>>

initLocalVar(type, name, init) ::= <<
<type> <name><if(init)> = <init><elseif(cxxTypeInitMap.(type))> = <cxxTypeInitMap.(type)><endif>;
>>

ruleLabelDefs() ::= <<
<[ruleDescriptor.tokenLabels,ruleDescriptor.tokenListLabels]
    :{it |<labelType> <it.label.text>;//}; separator="\n"
>
<ruleDescriptor.tokenListLabels:{it|std::vector\<antlr3::CommonTokenPtr> list_<it.label.text>;}; separator="\n">
<ruleDescriptor.ruleListLabels:{it|std::vector\<<ASTLabelType>\> list_<it.label.text>;}; separator="\n">
<[ruleDescriptor.ruleLabels,ruleDescriptor.ruleListLabels]
    :ruleLabelDef(); separator="\n"
>
>>

ruleLabelInitializations() ::= <<
<[ruleDescriptor.ruleLabels,ruleDescriptor.ruleListLabels]
    :ruleLabelInitVal(); separator="\n"
>
>>

lexerRuleLabelDefs() ::= <<
<[ruleDescriptor.tokenLabels,
  ruleDescriptor.tokenListLabels,
  ruleDescriptor.ruleLabels]
    :{it |<labelType> <it.label.text>;}; separator="\n"
>
<ruleDescriptor.charLabels:{it |std::uint32_t <it.label.text>;}; separator="\n">
<[ruleDescriptor.tokenListLabels,
  ruleDescriptor.ruleListLabels,
  ruleDescriptor.ruleListLabels]
    :{it |pANTLR3_INT_TRIE list_<it.label.text>;}; separator="\n"
>
>>

lexerRuleLabelInit() ::= <<
<[ruleDescriptor.tokenLabels,
  ruleDescriptor.tokenListLabels,
  ruleDescriptor.ruleLabels]
    :{it |<it.label.text> = NULL;}; separator="\n"
>
<[ruleDescriptor.tokenListLabels,
  ruleDescriptor.ruleListLabels,
  ruleDescriptor.ruleListLabels]
    :{it |list_<it.label.text> = antlr3IntTrieNew(31);}; separator="\n"
>
>>

lexerRuleLabelFree() ::= <<
<[ruleDescriptor.tokenLabels,
  ruleDescriptor.tokenListLabels,
  ruleDescriptor.ruleLabels]
    :{it |<it.label.text> = NULL;}; separator="\n"
>
<[ruleDescriptor.tokenListLabels,
  ruleDescriptor.ruleListLabels,
  ruleDescriptor.ruleListLabels]
    :{it |list_<it.label.text>->free(list_<it.label.text>);}; separator="\n"
>
>>

ruleReturnValue() ::= <%
<if(!ruleDescriptor.isSynPred)>
<if(ruleDescriptor.hasReturnValue)>
<if(ruleDescriptor.hasSingleReturnValue)>
<ruleDescriptor.singleValueReturnName>
<else>
retval
<endif>
<endif>
<endif>
%>

memoize() ::= <<
<if(memoize)>
<if(backtracking)>
if ( state_->backtracking > 0 ) { memoize(<ruleDescriptor.index>, <ruleDescriptor.name>_StartIndex); }
<endif>
<endif>
>>

ruleCleanUp() ::= <<

// This is where rules clean up and exit
//
goto rule<ruleDescriptor.name>Ex; /* Prevent compiler warnings */
rule<ruleDescriptor.name>Ex: ;
<if(ruleDescriptor.hasMultipleReturnValues)>
<if(!TREE_PARSER)>
<if(!ruleDescriptor.isSynPred)>
retval.stop = LT(-1);<\n>
<endif>
<endif>
<endif>
>>

scopeClean() ::= <<
<ruleDescriptor.useScopes:{it |<scopeStack(sname=it,...)>.pop_back();}; separator="\n">
<ruleDescriptor.ruleScope:{it |<scopeStack(sname=it.name,...)>.pop_back();}; separator="\n">

>>
/** How to generate a rule in the lexer; naked blocks are used for
 *  fragment rules, which do not produce tokens.
 */
lexerRule(ruleName,nakedBlock,ruleDescriptor,block,memoize) ::= <<
//   Comes from: <block.description>
/** \brief Lexer rule generated by ANTLR3
 *
 * $ANTLR start <ruleName>
 *
 * Looks to match the characters the constitute the token <ruleName>
 * from the attached input stream.
 *
 *
 * \remark
 *  - lexer->error == true if an exception was thrown.
 */
void <name>::m<ruleName>(<ruleDescriptor.parameterScope:parameterScope()>)
{
    <ruleDeclarations()>
    <ruleDescriptor.actions.declarations>
    <lexerRuleLabelDefs()>
    <if(trace)>traceIn(ANTLR3_T("m<ruleName>"), <ruleDescriptor.index>);<endif>

<if(nakedBlock)>
    <ruleMemoization(rname=ruleName)>
    <lexerRuleLabelInit()>
    <ruleDescriptor.actions.init>

    <block><\n>
<else>
    <ruleMemoization(rname=ruleName)>
    <lexerRuleLabelInit()>
    std::uint32_t _type	= <ruleName>;

    <ruleDescriptor.actions.init>

    <block>
	state_->type = _type;
<endif>
    <if(trace)>traceOut(ANTLR3_T("m<ruleName>"), <ruleDescriptor.index>);<endif>
    <ruleCleanUp()>
    <lexerRuleLabelFree()>
    <(ruleDescriptor.actions.after):execAfter()>
    <memoize>
}
// $ANTLR end <ruleName>
>>

/** How to generate code for the implicitly-defined lexer grammar rule
 *  that chooses between lexer rules.
 */
tokensRule(ruleName,nakedBlock,args,block,ruleDescriptor) ::= <<
/** This is the entry point in to the lexer from an object that
 *  wants to generate the next token, such as a pCOMMON_TOKEN_STREAM
 */
void <name>::mTokens()
{
    <block><\n>

    goto ruleTokensEx; /* Prevent compiler warnings */
ruleTokensEx: ;
}
>>

// S U B R U L E S

/** A (...) subrule with multiple alternatives */
block(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<

// <fileName>:<description>
{
    int alt<decisionNumber>=<maxAlt>;
    <decls>
    <@predecision()>
    <decision>
    <@postdecision()>
    <@prebranch()>
    switch (alt<decisionNumber>)
    {
	<alts:{a | <altSwitchCase(i,a)>}>
    }
    <@postbranch()>
}
>>

/** A rule block with multiple alternatives */
ruleBlock(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<
{
    //  <fileName>:<description>

    std::uint32_t alt<decisionNumber> = <maxAlt>;

    <decls>
    <@predecision()>
    <decision>
    <@postdecision()>
    switch (alt<decisionNumber>)
    {
	<alts:{a | <altSwitchCase(i,a)>}>
    }
}
>>

ruleBlockSingleAlt(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,description) ::= <<
// <fileName>:<description>
<decls>
<@prealt()>
<alts>
<@postalt()>
>>

/** A special case of a (...) subrule with a single alternative */
blockSingleAlt(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,description) ::= <<
// <fileName>:<description>
<decls>
<@prealt()>
<alts>
<@postalt()>
>>

/** A (..)+ block with 1 or more alternatives */
positiveClosureBlock(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<
// <fileName>:<description>
{
    int cnt<decisionNumber>=0;
    <decls>
    <@preloop()>

    for (;;)
    {
        int alt<decisionNumber>=<maxAlt>;
	<@predecision()>
	<decision>
	<@postdecision()>
	switch (alt<decisionNumber>)
	{
	    <alts:{a | <altSwitchCase(i,a)>}>
	    default:

		if ( cnt<decisionNumber> >= 1 )
		{
		    goto loop<decisionNumber>;
		}
		<ruleBacktrackFailure()>
		<earlyExitEx()>
		<@earlyExitException()>
		goto rule<ruleDescriptor.name>Ex;
	}
	cnt<decisionNumber>++;
    }
    loop<decisionNumber>: ;	/* Jump to here if this rule does not match */
    <@postloop()>
}
>>

earlyExitEx() ::= <<
/* mismatchedSetEx()
 */
recordException(new antlr3::EarlyExitException());
<\n>
>>
positiveClosureBlockSingleAlt ::= positiveClosureBlock

/** A (..)* block with 1 or more alternatives */
closureBlock(alts,decls,decision,enclosingBlockLevel,blockLevel,decisionNumber,maxK,maxAlt,description) ::= <<

// <fileName>:<description>
<decls>

<@preloop()>
for (;;)
{
    int alt<decisionNumber>=<maxAlt>;
    <@predecision()>
    <decision>
    <@postdecision()>
    switch (alt<decisionNumber>)
    {
	<alts:{a | <altSwitchCase(i,a)>}>
	default:
	    goto loop<decisionNumber>;	/* break out of the loop */
	    break;
    }
}
loop<decisionNumber>: ; /* Jump out to here if this rule does not match */
<@postloop()>
>>

closureBlockSingleAlt ::= closureBlock

/** Optional blocks (x)? are translated to (x|) by antlr before code generation
 *  so we can just use the normal block template
 */
optionalBlock ::= block

optionalBlockSingleAlt ::= block

/** A case in a switch that jumps to an alternative given the alternative
 *  number.  A DFA predicts the alternative and then a simple switch
 *  does the jump to the code that actually matches that alternative.
 */
altSwitchCase(altNum,alt) ::= <<
case <altNum>:
    <@prealt()>
    <alt>
    break;<\n>
>>

/** An alternative is just a list of elements; at outermost level */
alt(elements,altNum,description,autoAST,outerAlt,treeLevel,rew) ::= <<
// <fileName>:<description>
{
    <@declarations()>
    <@initializations()>
    <elements:element()>
    <rew>
    <@cleanup()>
}
>>

// E L E M E N T S
/** What to emit when there is no rewrite.  For auto build
 *  mode, does nothing.
 */
noRewrite(rewriteBlockLevel, treeLevel) ::= ""

/** Dump the elements one per line */
element(e) ::= <<
<@prematch()>
<e.el><\n>
>>

/** match a token optionally with a label in front */
tokenRef(token,label,elementIndex,terminalOptions) ::= <<
<if(label)><label> = antlr3::pointer_cast\< <labelType> >(<endif> match(<token>, FOLLOW_<token>_in_<ruleName><elementIndex>)<if(label)>)<endif>;
<checkRuleBacktrackFailure()>
>>

/** ids+=ID */
tokenRefAndListLabel(token,label,elementIndex,terminalOptions) ::= <<
<tokenRef(...)>
<listLabel(elem=label,...)>
>>

listLabel(label,elem) ::= <<
list_<label>.push_back(<elem>);
>>


/** match a character */
charRef(char,label) ::= <<
<if(label)>
<label> = LA(1);<\n>
<endif>
matchc(<char>);
<checkRuleBacktrackFailure()>
>>

/** match a character range */
charRangeRef(a,b,label) ::= <<
<if(label)>
<label> = LA(1);<\n>
<endif>
matchRange(<a>, <b>);
<checkRuleBacktrackFailure()>
>>

/** For now, sets are interval tests and must be tested inline */
matchSet(s,label,elementIndex,terminalOptions,postmatchCode="") ::= <<
<if(label)>
<if(LEXER)>
<label>= LA(1);<\n>
<else>
<label>=(<labelType>)LT(1);<\n>
<endif>
<endif>
if ( <s> )
{
    input_->consume();
    <postmatchCode>
<if(!LEXER)>
    state_->errorRecovery=false;
<endif>
    <if(backtracking)>state_->failed = false;<\n><endif>
}
else
{
    <ruleBacktrackFailure()>
    <mismatchedSetEx()>
    <@mismatchedSetException()>
<if(LEXER)>
    recover();
<else>
    recoverFromMismatchedSet(FOLLOW_set_in_<ruleName><elementIndex>);
<endif>
    goto rule<ruleDescriptor.name>Ex;
}<\n>
>>

mismatchedSetEx() ::= <<
recordException(new antlr3::MismatchedSetException(<if(PARSER)>FOLLOW_set_in_<ruleName><elementIndex><else>/*nullptr*/<endif>));
>>

matchRuleBlockSet ::= matchSet

matchSetAndListLabel(s,label,elementIndex,postmatchCode) ::= <<
<matchSet(...)>
<listLabel(elem=label,...)>
>>

/** Match a string literal */
lexerStringRef(string,label,elementIndex) ::= <<
<if(label)>
<label>Start = charIndex();
matchs(<string>);
<checkRuleBacktrackFailure()>
<label> = state_->tokFactory->newToken(state_->tokFactory);
<label>->setType(<label>, TokenInvalid);
<label>->setStartIndex(<label>, <label>Start);
<label>->setStopIndex(<label>, charIndex()-1);
<label>->input = INPUT->tnstream->istream;
<else>
matchs(<string>);
<checkRuleBacktrackFailure()><\n>
<endif>
>>

wildcard(token,label,elementIndex,terminalOptions) ::= <<
<if(label)>
<label>=(<labelType>)LT(1);<\n>
<endif>
matchAny();
<checkRuleBacktrackFailure()>
>>

wildcardAndListLabel(token,label,elementIndex,terminalOptions) ::= <<
<wildcard(...)>
<listLabel(elem=label,...)>
>>

/** Match . wildcard in lexer */
wildcardChar(label, elementIndex) ::= <<
<if(label)>
<label> = LA(1);<\n>
<endif>
matchAny();
<checkRuleBacktrackFailure()>
>>

wildcardCharListLabel(label, elementIndex) ::= <<
<wildcardChar(...)>
<listLabel(elem=label,...)>
>>

/** Match a rule reference by invoking it possibly with arguments
 *  and a return value or values. The 'rule' argument was the
 *  target rule name, but now is type Rule, whose toString is
 *  same: the rule name.  Now though you can access full rule
 *  descriptor stuff.
 */
ruleRef(rule,label,elementIndex,args,scope) ::= <<
followPush(&FOLLOW_<rule.name>_in_<ruleName><elementIndex>);
<if(label)><label>=<endif><if(scope)>ctx-><scope:delegateName()>-><endif><rule.name>(<if(scope)>-><scope:delegateName()><endif><if(args)><args; separator=", "><endif>);<\n>
followPop();
<checkRuleBacktrackFailure()>
>>

/** ids+=r */
ruleRefAndListLabel(rule,label,elementIndex,args,scope) ::= <<
<ruleRef(...)>
<listLabel(elem=label,...)>
>>

/** A lexer rule reference
 *  The 'rule' argument was the target rule name, but now
 *  is type Rule, whose toString is same: the rule name.
 *  Now though you can access full rule descriptor stuff.
 */
lexerRuleRef(rule,label,args,elementIndex,scope) ::= <<
/* <description> */
<if(label)>
{
    antlr3::Index <label>Start<elementIndex> = charIndex();
    <if(scope)>ctx-><scope:delegateName()>-><endif>m<rule.name>(<if(scope)>-><scope:delegateName()><endif> <if(args)>, <endif><args; separator=", ">);
    <checkRuleBacktrackFailure()>
    <label> = state_->tokFactory->newToken(state_->tokFactory);
    <label>->setType(<label>, TokenInvalid);
    <label>->setStartIndex(<label>, <label>Start<elementIndex>);
    <label>->setStopIndex(<label>, charIndex()-1);
    <label>->input = INPUT;
}
<else>
<if(scope)>ctx-><scope:delegateName()>-><endif>m<rule.name>(<if(scope)>-><scope:delegateName()><endif> <if(args)>, <endif><args; separator=", ">);
<checkRuleBacktrackFailure()>
<endif>
>>

/** i+=INT in lexer */
lexerRuleRefAndListLabel(rule,label,args,elementIndex,scope) ::= <<
<lexerRuleRef(...)>
<listLabel(elem=label,...)>
>>

/** EOF in the lexer */
lexerMatchEOF(label,elementIndex) ::= <<
<if(label)>
{
    <labelType> <label>;
    std::uint32_t <label>Start<elementIndex> = charIndex();
    matchc(CharstreamEof);
    <checkRuleBacktrackFailure()>
    <label> = state_->tokFactory->newToken(state_->tokFactory);
    <label>->setType(<label>, TokenEof);
    <label>->setStartIndex(<label>, <label>Start<elementIndex>);
    <label>->setStopIndex(<label>, charIndex()-1);
    <label>->input = INPUT->tnstream->istream;
}
<else>
    matchc(CharstreamEof);
    <checkRuleBacktrackFailure()>
    <endif>
>>

// used for left-recursive rules
recRuleDefArg()                       ::= "int <recRuleArg()>"
recRuleArg()                          ::= "_p"
recRuleAltPredicate(ruleName,opPrec)  ::= "<recRuleArg()> \<= <opPrec>"
recRuleSetResultAction()              ::= "root_0=$<ruleName>_primary.tree;"
recRuleSetReturnAction(src,name)      ::= "$<name>=$<src>.<name>;"

/** match ^(root children) in tree parser */
tree(root, actionsAfterRoot, children, nullableChildList, enclosingTreeLevel, treeLevel) ::= <<
<root:element()>
<actionsAfterRoot:element()>
<if(nullableChildList)>
if ( LA(1)==antlr3::TokenDown ) {
    match(antlr3::TokenDown, antlr3::Bitset());
    <checkRuleBacktrackFailure()>
    <children:element()>
    match(antlr3::TokenUp, antlr3::Bitset());
    <checkRuleBacktrackFailure()>
}
<else>
match(antlr3::TokenDown, antlr3::Bitset());
<checkRuleBacktrackFailure()>
<children:element()>
match(antlr3::TokenUp, antlr3::Bitset());
<checkRuleBacktrackFailure()>
<endif>
>>

/** Every predicate is used as a validating predicate (even when it is
 *  also hoisted into a prediction expression).
 */
validateSemanticPredicate(pred,description) ::= <<
if ( !(<evalPredicate(...)>) )
{
    <ruleBacktrackFailure()>
    <newFPE(...)>
}
>>

newFPE() ::= <<
    recordException(new antlr3::FailedPredicateException(ANTLR3_T("<description>"), ANTLR3_T("<ruleName>")));
    <\n>
>>

// F i x e d  D F A  (if-then-else)

dfaState(k,edges,eotPredictsAlt,description,stateNumber,semPredState) ::= <<

{
    int LA<decisionNumber>_<stateNumber> = LA(<k>); (void)LA<decisionNumber>_<stateNumber>;
    <edges; separator="\nelse ">
    else
    {
<if(eotPredictsAlt)>
        alt<decisionNumber>=<eotPredictsAlt>;
<else>
        <ruleBacktrackFailure()>

        <newNVException()>
        goto rule<ruleDescriptor.name>Ex;

<endif>
    }
}
>>

newNVException() ::= <<
recordException(new antlr3::NoViableAltException(ANTLR3_T("<description>"), <decisionNumber>, <stateNumber>));
<@noViableAltException()>
<\n>
>>

/** Same as a normal DFA state except that we don't examine lookahead
 *  for the bypass alternative.  It delays error detection but this
 *  is faster, smaller, and more what people expect.  For (X)? people
 *  expect "if ( LA(1)==X ) match(X);" and that's it.
 */
dfaOptionalBlockState(k,edges,eotPredictsAlt,description,stateNumber,semPredState) ::= <<
{
    int LA<decisionNumber>_<stateNumber> = LA(<k>);
    <edges; separator="\nelse ">
}
>>

/** A DFA state that is actually the loopback decision of a closure
 *  loop.  If end-of-token (EOT) predicts any of the targets then it
 *  should act like a default clause (i.e., no error can be generated).
 *  This is used only in the lexer so that for ('a')* on the end of a rule
 *  anything other than 'a' predicts exiting.
 */

dfaLoopbackStateDecls()::= <<
std::uint32_t LA<decisionNumber>_<stateNumber>;
>>
dfaLoopbackState(k,edges,eotPredictsAlt,description,stateNumber,semPredState) ::= <<
{
   /* dfaLoopbackState(k,edges,eotPredictsAlt,description,stateNumber,semPredState)
    */
    int LA<decisionNumber>_<stateNumber> = LA(<k>);
    <edges; separator="\nelse "><\n>
    <if(eotPredictsAlt)>
    <if(!edges)>
	alt<decisionNumber>=<eotPredictsAlt>; <! if no edges, don't gen ELSE !>
	<else>
    else
    {
	alt<decisionNumber>=<eotPredictsAlt>;
    }<\n>
    <endif>
    <endif>
}
>>

/** An accept state indicates a unique alternative has been predicted */
dfaAcceptState(alt) ::= "alt<decisionNumber>=<alt>;"

/** A simple edge with an expression.  If the expression is satisfied,
 *  enter to the target state.  To handle gated productions, we may
 *  have to evaluate some predicates for this edge.
 */
dfaEdge(labelExpr, targetState, predicates) ::= <<
if (true && <if(predicates)>(<predicates>) && <endif>(<labelExpr>))
{
    <targetState>
}
>>

// F i x e d  D F A  (switch case)

/** A DFA state where a SWITCH may be generated.  The code generator
 *  decides if this is possible: CodeGenerator.canGenerateSwitch().
 */
dfaStateSwitch(k,edges,eotPredictsAlt,description,stateNumber,semPredState) ::= <<
switch ( LA(<k>) )
{
<edges; separator="\n">

default:
<if(eotPredictsAlt)>
    alt<decisionNumber>=<eotPredictsAlt>;
<else>
    <ruleBacktrackFailure()>
    <newNVException()>
    goto rule<ruleDescriptor.name>Ex;<\n>
<endif>
}<\n>
>>

dfaOptionalBlockStateSwitch(k,edges,eotPredictsAlt,description,stateNumber,semPredState) ::= <<
switch ( LA(<k>) )
{
    <edges; separator="\n">
}<\n>
>>

dfaLoopbackStateSwitch(k, edges,eotPredictsAlt,description,stateNumber,semPredState) ::= <<
switch ( LA(<k>) )
{
<edges; separator="\n"><\n>
<if(eotPredictsAlt)>
default:
    alt<decisionNumber>=<eotPredictsAlt>;
    break;<\n>
<endif>
}<\n>
>>

dfaEdgeSwitch(labels, targetState) ::= <<
<labels:{it |case <it>:}; separator="\n">
	{
		<targetState>
	}
    break;
>>

// C y c l i c  D F A

/** The code to initiate execution of a cyclic DFA; this is used
 *  in the rule to predict an alt just like the fixed DFA case.
 *  The <name> attribute is inherited via the parser, lexer, ...
 */
dfaDecision(decisionNumber,description) ::= <<
alt<decisionNumber> = cdfa<decisionNumber>.predict(this, this, input_.get());
<checkRuleBacktrackFailure()>
>>

/* Dump DFA tables as static initialized arrays of shorts(16 bits)/characters(8 bits)
 * which are then used to statically initialize the dfa structure, which means that there
 * is no runtime initialization whatsoever, other than anything the C compiler might
 * need to generate. In general the C compiler will lay out memory such that there is no
 * runtime code required.
 */
cyclicDFA(dfa) ::= <<
/** Static dfa state tables for Cyclic dfa:
 *    <dfa.description>
 */
static const std::int32_t dfa<dfa.decisionNumber>_eot[<dfa.numberOfStates>] = {
	<dfa.eot; wrap="\n", separator=", ", null="-1">
};
static const std::int32_t dfa<dfa.decisionNumber>_eof[<dfa.numberOfStates>] = {
	<dfa.eof; wrap="\n", separator=", ", null="-1">
};
static const std::int32_t dfa<dfa.decisionNumber>_min[<dfa.numberOfStates>] = {
	<dfa.min; wrap="\n", separator=", ", null="-1">
};
static const std::int32_t dfa<dfa.decisionNumber>_max[<dfa.numberOfStates>] = {
	<dfa.max; wrap="\n", separator=", ", null="-1">
};
static const std::int32_t dfa<dfa.decisionNumber>_accept[<dfa.numberOfStates>] = {
	<dfa.accept; wrap="\n", separator=", ", null="-1">
};
static const std::int32_t dfa<dfa.decisionNumber>_special[<dfa.numberOfStates>] = {
	<dfa.special; wrap="\n", separator=", ", null="-1">
};

<dfa.edgeTransitionClassMap.keys:{ table |
static const std::int32_t dfa<dfa.decisionNumber>_T<i0>[] = {
	<table; separator=", ", wrap="\n", null="-1">
\};<\n>}; null = "">

/* Transition tables are a table of sub tables, with some tables
 * reused for efficiency.
 */
static const std::int32_t * const dfa<dfa.decisionNumber>_transitions[] = {
    <dfa.transitionEdgeTables:{xref|dfa<dfa.decisionNumber>_T<xref>}; separator=", ", wrap="\n", null="NULL">
};

<if(dfa.specialStateSTs)>
std::int32_t <name>::dfa<dfa.decisionNumber>_sst(antlr3::BaseRecognizer * recognizer, antlr3::IntStream * is, std::int32_t s, antlr3::MarkerPtr marker)
{
    std::int32_t _s	    = s;
    switch  (s)
    {
    <dfa.specialStateSTs:{state |
    case <i0>:

	<state>}; separator="\n">
    }
<if(backtracking)>
    if (state_->backtracking > 0)
    {
        state_->failed = true;
        return -1;
    }
<endif>

    recordException(new antlr3::NoViableAltException(ANTLR3_T("<dfa.description>"), <dfa.decisionNumber>, _s));
    <@noViableAltException()>
    return -1;
}
<endif>

<@errorMethod()>

/* Declare tracking structure for Cyclic DFA <dfa.decisionNumber>
 */
static antlr3::CyclicDfa const cdfa<dfa.decisionNumber> = {
    // Decision number of this dfa
    <dfa.decisionNumber>,
    // Which decision this represents:
    ANTLR3_T("<dfa.description>"),
    // Special state transition function
<if(dfa.specialStateSTs)>
    &<name>_SST_Func_Provider::dfa<dfa.decisionNumber>_sst,
<else>
    NULL,
<endif>
    // EOT table
    dfa<dfa.decisionNumber>_eot,
    // EOF table
    dfa<dfa.decisionNumber>_eof,
    // Minimum tokens for each state
    dfa<dfa.decisionNumber>_min,
    // Maximum tokens for each state
    dfa<dfa.decisionNumber>_max,
    // Accept table
    dfa<dfa.decisionNumber>_accept,
    // Special transition states
    dfa<dfa.decisionNumber>_special,
    // Table of transition tables
    dfa<dfa.decisionNumber>_transitions
};
/* End of Cyclic DFA <dfa.decisionNumber>
 * ---------------------
 */
>>

declDFA_SST(dfa) ::= <<
<if(dfa.specialStateSTs)>
std::int32_t dfa<dfa.decisionNumber>_sst(antlr3::BaseRecognizer * recognizer, antlr3::IntStream * is, std::int32_t s, antlr3::MarkerPtr marker);
<endif>
>>

dfa_sst_func(dfa) ::= <<
<if(dfa.specialStateSTs)>
    static std::int32_t dfa<dfa.decisionNumber>_sst(void * ctx, antlr3::BaseRecognizer * recognizer, antlr3::IntStream * is, std::int32_t s, antlr3::MarkerPtr marker)
    {
        return reinterpret_cast\<<name> *>(ctx)->dfa<dfa.decisionNumber>_sst(recognizer, is, s, std::move(marker));
    }
<endif>
>>

/** A state in a cyclic DFA; it's a special state and part of a big switch on
 *  state.
 */
cyclicDFAState(decisionNumber,stateNumber,edges,needErrorClause,semPredState) ::= <<
{
    std::uint32_t LA<decisionNumber>_<stateNumber> = LA(1);<\n>
    <if(semPredState)> <! get next lookahead symbol to test edges, then rewind !>
    antlr3::Index index<decisionNumber>_<stateNumber> = input_->index();<\n>
    marker->rewind();<\n>
    <endif>
    s = -1;
    <edges; separator="\nelse ">
	<if(semPredState)> <! return input cursor to state before we rewound !>
	input_->seek(index<decisionNumber>_<stateNumber>);<\n>
	<endif>
    if ( s>=0 )
    {
	return s;
    }
}
break;
>>

/** Just like a fixed DFA edge, test the lookahead and indicate what
 *  state to jump to next if successful.
 */
cyclicDFAEdge(labelExpr, targetStateNumber, edgeNumber, predicates) ::= <<
if (true && <if(predicates)>(<predicates>) && <endif>(<labelExpr>) )
{
    s = <targetStateNumber>;
}<\n>
>>

/** An edge pointing at end-of-token; essentially matches any char;
 *  always jump to the target.
 */
eotDFAEdge(targetStateNumber,edgeNumber, predicates) ::= <<
 s = <targetStateNumber>;<\n>
>>


// D F A  E X P R E S S I O N S

andPredicates(left,right) ::= "( (<left>) && (<right>) )"

orPredicates(operands) ::= "(<operands:{o|(<o>)}; separator=\"||\">)"

notPredicate(pred) ::= "!( <evalPredicate(pred,{})> )"

evalPredicate(pred,description) ::= "(<pred>)"

evalSynPredicate(pred,description) ::= "<pred>()"

lookaheadTest(atom,k,atomAsInt) ::= "LA<decisionNumber>_<stateNumber> == <atom>"

/** Sometimes a lookahead test cannot assume that LA(k) is in a temp variable
 *  somewhere.  Must ask for the lookahead directly.
 */
isolatedLookaheadTest(atom,k,atomAsInt) ::= "LA(<k>) == <atom>"

lookaheadRangeTest(lower,upper,k,rangeNumber,lowerAsInt,upperAsInt) ::= <%
isBetween(<lower>, LA<decisionNumber>_<stateNumber>, <upper>)
%>

isolatedLookaheadRangeTest(lower,upper,k,rangeNumber,lowerAsInt,upperAsInt) ::= "isBetween(<lower>, LA(<k>), <upper>)"

setTest(ranges) ::= "<ranges; separator=\" || \">"

// A T T R I B U T E S

makeScopeSet() ::= <<
struct <scopeType(sname=scope.name,...)>
{
    <scope.attributes:{it |<it.decl>;}; separator="\n">
};
>>

globalAttributeScopeDecl(scope) ::= <<
<if(scope)>
<if(scope.attributes)>
<makeScopeSet(...)>
<endif>
<endif>
>>

ruleAttributeScopeDecl(scope) ::= <<
<if(scope)>
<if(scope.attributes)>
<makeScopeSet(...)>
<endif>
<endif>
>>

globalAttributeScopeDef(scope) ::= <<
<if(scope.attributes)>
std::vector\< <scopeType(sname=scope.name,...)> > <scopeStack(sname=scope.name)>;
<endif>
>>

ruleAttributeScopeDef(scope) ::= <<
<if(scope.attributes)>
std::vector\< <scopeType(sname=scope.name,...)> > <scopeStack(sname=scope.name)>;
<endif>
>>

scopeType(sname) ::= <<
<name>_<sname>_SCOPE
>>

scopeStack(sname) ::= <<
<name>_<sname>_stack_
>>

returnStructName(r) ::= "<r.name>_return"

returnType() ::= <%
<if(!ruleDescriptor.isSynPred)>
<if(ruleDescriptor.hasMultipleReturnValues)>
<ruleDescriptor.grammar.recognizerName>_<ruleDescriptor:returnStructName()>
<else>
<if(ruleDescriptor.hasSingleReturnValue)>
<ruleDescriptor.singleValueReturnType>
<else>
void
<endif>
<endif>
<else>
bool
<endif>
%>

/** Generate the C type associated with a single or multiple return
 *  value(s).
 */
ruleLabelType(referencedRule) ::= <%
<if(referencedRule.hasMultipleReturnValues)>
<referencedRule.grammar.recognizerName>_<referencedRule.name>_return
<else>
<if(referencedRule.hasSingleReturnValue)>
<referencedRule.singleValueReturnType>
<else>
void
<endif>
<endif>
%>

delegateName(d) ::= <<
<if(d.label)><d.label><else>g<it.name><endif>
>>

/** Define a rule label  */
ruleLabelDef(label) ::= <<
<ruleLabelType(referencedRule=label.referencedRule)> <label.label.text>;<\n>
>>
/**  Rule label default value */
ruleLabelInitVal(label) ::= <<
>>

ASTLabelType() ::= "<if(recognizer.ASTLabelType)><recognizer.ASTLabelType><else>antlr3::ItemPtr<endif>"

/** Define a return struct for a rule if the code needs to access its
 *  start/stop tokens, tree stuff, attributes, ...  Leave a hole for
 *  subgroups to stick in members.
 */
returnScope(scope) ::= <<
<if(!ruleDescriptor.isSynPred)>
<if(ruleDescriptor.hasMultipleReturnValues)>
struct <ruleDescriptor.grammar.recognizerName>_<ruleDescriptor:returnStructName()>
{
<if(!TREE_PARSER)>
    /** Generic return elements for ANTLR3 rules that are not in tree parsers or returning trees
     */
    antlr3::CommonTokenPtr start;
    antlr3::CommonTokenPtr stop;
<else>
    <recognizer.ASTLabelType> start;
    <recognizer.ASTLabelType> stop;
<endif>
    <@ruleReturnMembers()>
    <ruleDescriptor.returnScope.attributes:{it |<it.type> <it.name>;}; separator="\n">
};
<endif>
<endif>
>>

parameterScope(scope) ::= <<
<scope.attributes:{it |<it.decl>}; separator=", ">
>>

parameterAttributeRef(attr) ::= "<attr.name>"
parameterSetAttributeRef(attr,expr) ::= "<attr.name>=<expr>;"

/** Note that the scopeAttributeRef does not have access to the
 * grammar name directly
 */
scopeAttributeRef(scope,attr,index,negIndex) ::= <%
<if(negIndex)>
    <scopeStack(sname=scope,...)>[<scopeStack(sname=scope,...)>.size() - <negIndex> - 1].<attr.name>
<else>
<if(index)>
    <scopeStack(sname=scope,...)>[<index>].<attr.name>
<else>
    <scopeStack(sname=scope,...)>.back().<attr.name>
<endif>
<endif>
%>

scopeSetAttributeRef(scope,attr,expr,index,negIndex) ::= <%
<if(negIndex)>
    <scopeStack(sname=scope,...)>[<scopeStack(sname=scope,...)>.size() - <negIndex> - 1].<attr.name> = <expr>;
<else>
<if(index)>
    <scopeStack(sname=scope,...)>[<index>].<attr.name> =<expr>;
<else>
    <scopeStack(sname=scope,...)>.back().<attr.name> =<expr>;
<endif>
<endif>
%>

/** $x is either global scope or x is rule with dynamic scope; refers
 *  to stack itself not top of stack.  This is useful for predicates
 *  like {$function.size()>0 && $function::name.equals("foo")}?
 */
isolatedDynamicScopeRef(scope) ::= "ctx->SCOPE_STACK(<scope>)"

/** reference an attribute of rule; might only have single return value */
ruleLabelRef(referencedRule,scope,attr) ::= <%
<if(referencedRule.hasMultipleReturnValues)>
<scope>.<attr.name>
<else>
<scope>
<endif>
%>

returnAttributeRef(ruleDescriptor,attr) ::= <%
<if(ruleDescriptor.hasMultipleReturnValues)>
retval.<attr.name>
<else>
<attr.name>
<endif>
%>

returnSetAttributeRef(ruleDescriptor,attr,expr) ::= <<
<if(ruleDescriptor.hasMultipleReturnValues)>
retval.<attr.name>=<expr>;
<else>
<attr.name>=<expr>;
<endif>
>>

/** How to translate $tokenLabel */
tokenLabelRef(label) ::= "<label>"

/** ids+=ID {$ids} or e+=expr {$e} */
listLabelRef(label) ::= "list_<label>"


// not sure the next are the right approach
//
tokenLabelPropertyRef_text(scope,attr) ::= <%
<if(TREE_PARSER)>
adaptor_->getText(<scope>)
<else>
<scope>->text()
<endif>
%>
tokenLabelPropertyRef_type(scope,attr) ::= "<scope>->type()"
tokenLabelPropertyRef_line(scope,attr) ::= "<scope>->line()"
tokenLabelPropertyRef_pos(scope,attr) ::= "<scope>->charPositionInLine()"
tokenLabelPropertyRef_channel(scope,attr) ::= "<scope>->channel()"
tokenLabelPropertyRef_index(scope,attr) ::= "<scope>->tokenIndex()"
tokenLabelPropertyRef_tree(scope,attr) ::= "<scope>->tree"
tokenLabelPropertyRef_int(scope,attr) ::= "toInt32(<scope>->text())"

ruleLabelPropertyRef_start(scope,attr) ::= "<scope>.start"
ruleLabelPropertyRef_stop(scope,attr) ::= "<scope>.stop"
ruleLabelPropertyRef_tree(scope,attr) ::= "<scope>.tree"
ruleLabelPropertyRef_text(scope,attr) ::= <<
<if(TREE_PARSER)>
(treeNodeStream()->toString(<scope>.start, <scope>.start))
<else>
(tokenStream()->toString(<scope>.start, <scope>.stop))
<endif>
>>

ruleLabelPropertyRef_st(scope,attr) ::= "<scope>.st"

/** Isolated $RULE ref ok in lexer as it's a Token */
lexerRuleLabel(label) ::= "<label>"

lexerRuleLabelPropertyRef_type(scope,attr) ::= "<scope>->type()"
lexerRuleLabelPropertyRef_line(scope,attr) ::= "<scope>->line()"
lexerRuleLabelPropertyRef_pos(scope,attr) ::= "<scope>->charPositionInLine()"
lexerRuleLabelPropertyRef_channel(scope,attr) ::= "<scope>->channel()"
lexerRuleLabelPropertyRef_index(scope,attr) ::= "<scope>->tokenIndex()"
lexerRuleLabelPropertyRef_text(scope,attr) ::= "<scope>->text()"

// Somebody may ref $template or $tree or $stop within a rule:
rulePropertyRef_start(scope,attr) ::= "retval.start"
rulePropertyRef_stop(scope,attr) ::= "retval.stop"
rulePropertyRef_tree(scope,attr) ::= "retval.tree"
rulePropertyRef_text(scope,attr) ::= <<
<if(TREE_PARSER)>
treeNodeStream()->toString(adaptor_->getTokenStartIndex(retval.start), adaptor_->getTokenStopIndex(retval.start))
<else>
tokenStream()->toString(retval.start, LT(-1))
<endif>
>>
rulePropertyRef_st(scope,attr) ::= "retval.st"

lexerRulePropertyRef_text(scope,attr) ::= "LEXER->getText(LEXER)"
lexerRulePropertyRef_type(scope,attr) ::= "_type"
lexerRulePropertyRef_line(scope,attr) ::= "state_->tokenStartLine"
lexerRulePropertyRef_pos(scope,attr) ::= "state_->tokenStartCharPositionInLine"
lexerRulePropertyRef_channel(scope,attr) ::= "state_->channel"
lexerRulePropertyRef_start(scope,attr) ::= "state_->tokenStartCharIndex"
lexerRulePropertyRef_stop(scope,attr) ::= "(LEXER->getCharIndex(LEXER)-1)"
lexerRulePropertyRef_index(scope,attr) ::= "-1" // undefined token index in lexer
lexerRulePropertyRef_int(scope,attr) ::= "LEXER->getText(LEXER)->toInt32(LEXER->getText(LEXER))"


// setting $st and $tree is allowed in local rule. everything else is flagged as error
ruleSetPropertyRef_tree(scope,attr,expr) ::= "retval.tree=<expr>;"
ruleSetPropertyRef_st(scope,attr,expr) ::= "retval.st=<expr>;"


/** How to deal with an @after for C targets. Because we cannot rely on
 *  any garbage collection, after code is executed even in backtracking
 *  mode. Must be documented clearly.
 */
execAfter(action) ::= <<
{
    <action>
}
>>

/** How to execute an action (when not backtracking) */
execAction(action) ::= <<
<if(backtracking)>
<if(actions.(actionScope).synpredgate)>
if ( <actions.(actionScope).synpredgate> )
{
    <action>
}
<else>
if ( state_->backtracking == 0 )
{
    <action>
}
<endif>
<else>
{
    <action>
}
<endif>
>>

// M I S C (properties, etc...)

bitsetDeclare(name, words64) ::= <<
static antlr3::Bitset const <name> = antlr3::Bitset::fromData({ <words64:{it |<it>ull}; separator=", "> });<\n>
>>

codeFileExtension() ::= ".cpp"

true_value() ::= "true"
false_value() ::= "false"
